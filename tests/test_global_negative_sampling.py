#!/usr/bin/env python3
"""
Test script to demonstrate global negative sampling implementation.

This script shows how the new global negative sampling feature works
and compares it with the original in-batch sampling approach.
"""

import json
import tempfile
from pathlib import Path
from contrastive_learning.data_structures import TrainingConfig, TrainingSample
from contrastive_learning.data_loader import DataLoader
from contrastive_learning.batch_processor import BatchProcessor

def create_test_dataset():
    """Create a small test dataset to demonstrate the bias issue."""
    
    # Create diverse job types
    jobs = [
        {"job_id": "python_dev", "title": "Python Developer", "description": {"original": "Python programming"}},
        {"job_id": "java_dev", "title": "Java Developer", "description": {"original": "Java programming"}},
        {"job_id": "chef", "title": "Chef", "description": {"original": "Cooking and food preparation"}},
        {"job_id": "doctor", "title": "Doctor", "description": {"original": "Medical care and treatment"}},
        {"job_id": "teacher", "title": "Teacher", "description": {"original": "Education and instruction"}},
        {"job_id": "manager", "title": "Project Manager", "description": {"original": "Project management"}},
        {"job_id": "designer", "title": "UI Designer", "description": {"original": "User interface design"}},
        {"job_id": "analyst", "title": "Data Analyst", "description": {"original": "Data analysis"}},
    ]
    
    # Create resumes
    resumes = [
        {"experience": "Python developer with 5 years experience", "skills": [{"name": "Python"}]},
        {"experience": "Java developer with 3 years experience", "skills": [{"name": "Java"}]},
        {"experience": "Professional chef with culinary training", "skills": [{"name": "Cooking"}]},
        {"experience": "Medical doctor with hospital experience", "skills": [{"name": "Medicine"}]},
    ]
    
    # Create training samples
    samples = []
    sample_id = 1
    
    # Create positive samples (each resume matched with appropriate job)
    for i, resume in enumerate(resumes):
        sample = {
            "resume": resume,
            "job": jobs[i],  # Match resume to appropriate job
            "label": "positive",
            "sample_id": f"sample_{sample_id}",
            "metadata": {"job_applicant_id": f"applicant_{i}"}
        }
        samples.append(sample)
        sample_id += 1
    
    # Add more samples to create batches with different compositions
    # This will demonstrate the bias issue
    for i in range(4):  # Add 4 more copies with different job combinations
        for j, resume in enumerate(resumes):
            sample = {
                "resume": resume,
                "job": jobs[(j + i) % len(jobs)],  # Rotate job assignments
                "label": "positive",
                "sample_id": f"sample_{sample_id}",
                "metadata": {"job_applicant_id": f"applicant_{j}_{i}"}
            }
            samples.append(sample)
            sample_id += 1
    
    return samples

def test_negative_sampling_comparison():
    """Compare in-batch vs global negative sampling."""
    
    print("ðŸŽ¯ Testing Global Negative Sampling Implementation")
    print("=" * 60)
    
    # Create test dataset
    samples = create_test_dataset()
    
    # Write to temporary file
    with tempfile.NamedTemporaryFile(mode='w', suffix='.jsonl', delete=False) as f:
        for sample in samples:
            f.write(json.dumps(sample) + '\n')
        temp_file = f.name
    
    try:
        # Test configurations
        config_in_batch = TrainingConfig(
            batch_size=4,
            global_negative_sampling=False,  # Original in-batch sampling
            use_pathway_negatives=False  # Disable for cleaner comparison
        )
        
        config_global = TrainingConfig(
            batch_size=4,
            global_negative_sampling=True,   # New global sampling
            global_negative_pool_size=100,
            use_pathway_negatives=False  # Disable for cleaner comparison
        )
        
        # Initialize components
        data_loader = DataLoader(config_in_batch)
        
        print(f"ðŸ“Š Dataset: {len(samples)} samples")
        print(f"ðŸ”„ Batch size: {config_in_batch.batch_size}")
        print()
        
        # Test 1: In-batch negative sampling (original)
        print("ðŸ” Test 1: In-Batch Negative Sampling (Original)")
        print("-" * 50)
        
        batch_processor_in_batch = BatchProcessor(config_in_batch)
        
        batch_count = 0
        for batch in data_loader.load_batches(temp_file):
            batch_count += 1
            triplets = batch_processor_in_batch.process_batch(batch)
            
            print(f"Batch {batch_count}:")
            for i, triplet in enumerate(triplets):
                anchor_job = triplet.anchor.get('experience', 'Unknown')[:30]
                positive_job = triplet.positive.get('title', 'Unknown')
                negative_jobs = [neg.get('title', 'Unknown') for neg in triplet.negatives]
                
                print(f"  Triplet {i+1}: {anchor_job}... â†’ {positive_job}")
                print(f"    Negatives: {negative_jobs}")
                print(f"    Strategy: {triplet.view_metadata['sampling_strategy']}")
            print()
            
            if batch_count >= 3:  # Limit output for readability
                break
        
        # Test 2: Global negative sampling (new)
        print("ðŸŒ Test 2: Global Negative Sampling (New)")
        print("-" * 50)
        
        batch_processor_global = BatchProcessor(config_global)
        
        # Load global job pool
        global_job_pool = data_loader.load_global_job_pool(temp_file, max_jobs=100)
        print(f"Global job pool loaded: {len(global_job_pool)} unique jobs")
        print()
        
        batch_count = 0
        for batch in data_loader.load_batches(temp_file):
            batch_count += 1
            triplets = batch_processor_global.process_batch(batch, global_job_pool)
            
            print(f"Batch {batch_count}:")
            for i, triplet in enumerate(triplets):
                anchor_job = triplet.anchor.get('experience', 'Unknown')[:30]
                positive_job = triplet.positive.get('title', 'Unknown')
                negative_jobs = [neg.get('title', 'Unknown') for neg in triplet.negatives]
                
                print(f"  Triplet {i+1}: {anchor_job}... â†’ {positive_job}")
                print(f"    Negatives: {negative_jobs}")
                print(f"    Strategy: {triplet.view_metadata['sampling_strategy']}")
            print()
            
            if batch_count >= 3:  # Limit output for readability
                break
        
        print("âœ… Global negative sampling implementation successful!")
        print()
        print("ðŸŽ¯ Key Benefits Observed:")
        print("  â€¢ Consistent negative sampling across batches")
        print("  â€¢ Access to full dataset diversity")
        print("  â€¢ Reduced batch composition bias")
        print("  â€¢ Backward compatible (feature flag)")
        
    finally:
        # Clean up
        Path(temp_file).unlink()

if __name__ == "__main__":
    test_negative_sampling_comparison()